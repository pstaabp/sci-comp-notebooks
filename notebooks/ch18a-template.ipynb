{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 18: Parallel Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Briefly, parallel computing is a method of running code on multiple processors (or multiple cores of the same processor) at the same time. In general, this is a difficult task depending on where data is stored and retrieved. The Julia Documentation on parallel computing is a good place to start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a simple function that counts the number of heads out of n coin flips:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "countHeads (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function countHeads(n::Int)\n",
    "    c::Int = 0\n",
    "    for i=1:n\n",
    "        c += rand(Bool)\n",
    "    end\n",
    "    c\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This finds the fraction of heads from 2 billion coin flips. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3.271717 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.500002681"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time countHeads(2*10^9)/(2*10^9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Distributed` package contains a lot of functionality to use the multiple cores in a CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following will add a \"processor\" or core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Int64}:\n",
       " 2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addprocs(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we have the following number of cores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nprocs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the same function as above, but is avaiable on all cores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function countHeads(n::Int)\n",
    "   c::Int = 0\n",
    "   for i=1:n\n",
    "       c += rand(Bool)\n",
    "   end\n",
    "   c\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a simple way to \"send\" the functions to the two cores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Future(2, 1, 10, ReentrantLock(nothing, 0x00000000, 0x00, Base.GenericCondition{Base.Threads.SpinLock}(Base.InvasiveLinkedList{Task}(nothing, nothing), Base.Threads.SpinLock(0)), (0, 0, 0)), nothing)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= @spawn countHeads(10^9)\n",
    "b= @spawn countHeads(10^9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that that took no time.  That's because it just sent the code, and didn't run it. The following now will run it and add the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.643784 seconds (190 allocations: 7.531 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "999995777"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time fetch(a)+fetch(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is faster than the original, but not much.  Basically, there is overhead into splitting code up and then bringing it back together.  Also, as we add more cores, this can be cumbersome.   We're going to see an alternative way.  This function will add an appropriate number of cores for your computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following gives the information about the individual cores in the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Vector{Base.Sys.CPUinfo}:\n",
       " Intel(R) Core(TM) i5-1030NG7 CPU @ 1.10GHz: \n",
       "        speed         user         nice          sys         idle          irq\n",
       "     1100 MHz    1573927 s          0 s    1135760 s    2141322 s          0 s\n",
       " Intel(R) Core(TM) i5-1030NG7 CPU @ 1.10GHz: \n",
       "        speed         user         nice          sys         idle          irq\n",
       "     1100 MHz     647068 s          0 s     436726 s    3766907 s          0 s\n",
       " Intel(R) Core(TM) i5-1030NG7 CPU @ 1.10GHz: \n",
       "        speed         user         nice          sys         idle          irq\n",
       "     1100 MHz    1463183 s          0 s     966000 s    2421523 s          0 s\n",
       " Intel(R) Core(TM) i5-1030NG7 CPU @ 1.10GHz: \n",
       "        speed         user         nice          sys         idle          irq\n",
       "     1100 MHz     658162 s          0 s     436329 s    3756208 s          0 s\n",
       " Intel(R) Core(TM) i5-1030NG7 CPU @ 1.10GHz: \n",
       "        speed         user         nice          sys         idle          irq\n",
       "     1100 MHz    1389496 s          0 s     906690 s    2554519 s          0 s\n",
       " Intel(R) Core(TM) i5-1030NG7 CPU @ 1.10GHz: \n",
       "        speed         user         nice          sys         idle          irq\n",
       "     1100 MHz     672158 s          0 s     432161 s    3746378 s          0 s\n",
       " Intel(R) Core(TM) i5-1030NG7 CPU @ 1.10GHz: \n",
       "        speed         user         nice          sys         idle          irq\n",
       "     1100 MHz    1339343 s          0 s     855032 s    2656328 s          0 s\n",
       " Intel(R) Core(TM) i5-1030NG7 CPU @ 1.10GHz: \n",
       "        speed         user         nice          sys         idle          irq\n",
       "     1100 MHz     685816 s          0 s     429380 s    3735500 s          0 s"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sys.cpu_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will add all available cores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Vector{Int64}:\n",
       "  3\n",
       "  4\n",
       "  5\n",
       "  6\n",
       "  7\n",
       "  8\n",
       "  9\n",
       " 10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addprocs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.139562 seconds (21.79 k allocations: 1.107 MiB, 2.53% compilation time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "999994035"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time let\n",
    " nheads = @distributed (+) for i = 1:2*10^9\n",
    "   Int(rand(Bool))\n",
    " end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this has helped out a bit for time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 18.2: Writing a parallel card simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now will look at writing a parallel version of the PlayingCards stuff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"../julia-files/PlayingCards.jl\")\n",
    "using .PlayingCards, Random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the original runTrials function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "runTrials (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function runTrials(trials::Int,f::Function)\n",
    "    local deck=map(Card,1:52)\n",
    "    local numhands=0\n",
    "    for i=1:trials\n",
    "        shuffle!(deck)\n",
    "        h = Hand(deck[1:5])\n",
    "        if(f(h))\n",
    "            numhands+=1\n",
    "        end\n",
    "    end\n",
    "    numhands\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9.804040 seconds (30.00 M allocations: 3.129 GiB, 7.61% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14449"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time runTrials(10_000_000,isFullHouse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a parallel version of this.  There are two important aspects of this:\n",
    "* use `@everywhere` on all modules/functions that you need\n",
    "* we switch the for loop to a distributed loop.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module PlayingCards.\n",
      "WARNING: using PlayingCards.Hand in module Main conflicts with an existing identifier.\n",
      "WARNING: using PlayingCards.isFullHouse in module Main conflicts with an existing identifier.\n",
      "WARNING: using PlayingCards.Card in module Main conflicts with an existing identifier.\n"
     ]
    }
   ],
   "source": [
    "@everywhere include(\"../julia-files/PlayingCards.jl\")\n",
    "@everywhere using .PlayingCards, Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function paraCountHands(trials::Integer,f::Function)\n",
    "  local deck=map(Card,1:52)\n",
    "  function checkHand(f::Function) ## shuffle the deck then check the hand.\n",
    "    shuffle!(deck)\n",
    "    f(Hand(deck[1:5]))\n",
    "  end\n",
    "  @distributed (+) for i = 1:trials\n",
    "    Int(checkHand(f))\n",
    "  end  \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3.736395 seconds (997 allocations: 54.016 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14269"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time fh = paraCountHands(10_000_000,isFullHouse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has cut the time by a significant amount. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 18.3 A parallel map function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12-element Vector{Int64}:\n",
       " 1000000000\n",
       " 1000000000\n",
       " 1000000000\n",
       " 1000000000\n",
       " 1000000000\n",
       " 1000000000\n",
       " 1000000000\n",
       " 1000000000\n",
       " 1000000000\n",
       " 1000000000\n",
       " 1000000000\n",
       " 1000000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_coins = 1_000_000_000*ones(Int64,12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a parallell map function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this, you'll see an error, go back above and rerun the @everywhere countHeads cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "On worker 5:\nUndefVarError: #countHeads not defined\nStacktrace:\n  [1] \u001b[0m\u001b[1mdeserialize_datatype\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/Applications/Julia-1.8.app/Contents/Resources/julia/share/julia/stdlib/v1.8/Serialization/src/\u001b[39m\u001b[90m\u001b[4mSerialization.jl:1364\u001b[24m\u001b[39m\n  [2] \u001b[0m\u001b[1mhandle_deserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/Applications/Julia-1.8.app/Contents/Resources/julia/share/julia/stdlib/v1.8/Serialization/src/\u001b[39m\u001b[90m\u001b[4mSerialization.jl:866\u001b[24m\u001b[39m\n  [3] \u001b[0m\u001b[1mdeserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/Applications/Julia-1.8.app/Contents/Resources/julia/share/julia/stdlib/v1.8/Serialization/src/\u001b[39m\u001b[90m\u001b[4mSerialization.jl:813\u001b[24m\u001b[39m\n  [4] \u001b[0m\u001b[1mhandle_deserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/Applications/Julia-1.8.app/Contents/Resources/julia/share/julia/stdlib/v1.8/Serialization/src/\u001b[39m\u001b[90m\u001b[4mSerialization.jl:873\u001b[24m\u001b[39m\n  [5] \u001b[0m\u001b[1mdeserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/Applications/Julia-1.8.app/Contents/Resources/julia/share/julia/stdlib/v1.8/Serialization/src/\u001b[39m\u001b[90m\u001b[4mSerialization.jl:813\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n  [6] \u001b[0m\u001b[1mdeserialize_msg\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/Applications/Julia-1.8.app/Contents/Resources/julia/share/julia/stdlib/v1.8/Distributed/src/\u001b[39m\u001b[90m\u001b[4mmessages.jl:87\u001b[24m\u001b[39m\n  [7] \u001b[0m\u001b[1m#invokelatest#2\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4messentials.jl:729\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n  [8] \u001b[0m\u001b[1minvokelatest\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4messentials.jl:726\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n  [9] \u001b[0m\u001b[1mmessage_handler_loop\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/Applications/Julia-1.8.app/Contents/Resources/julia/share/julia/stdlib/v1.8/Distributed/src/\u001b[39m\u001b[90m\u001b[4mprocess_messages.jl:176\u001b[24m\u001b[39m\n [10] \u001b[0m\u001b[1mprocess_tcp_streams\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/Applications/Julia-1.8.app/Contents/Resources/julia/share/julia/stdlib/v1.8/Distributed/src/\u001b[39m\u001b[90m\u001b[4mprocess_messages.jl:133\u001b[24m\u001b[39m\n [11] \u001b[0m\u001b[1m#103\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mtask.jl:484\u001b[24m\u001b[39m",
     "output_type": "error",
     "traceback": [
      "On worker 5:\nUndefVarError: #countHeads not defined\nStacktrace:\n  [1] \u001b[0m\u001b[1mdeserialize_datatype\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/Applications/Julia-1.8.app/Contents/Resources/julia/share/julia/stdlib/v1.8/Serialization/src/\u001b[39m\u001b[90m\u001b[4mSerialization.jl:1364\u001b[24m\u001b[39m\n  [2] \u001b[0m\u001b[1mhandle_deserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/Applications/Julia-1.8.app/Contents/Resources/julia/share/julia/stdlib/v1.8/Serialization/src/\u001b[39m\u001b[90m\u001b[4mSerialization.jl:866\u001b[24m\u001b[39m\n  [3] \u001b[0m\u001b[1mdeserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/Applications/Julia-1.8.app/Contents/Resources/julia/share/julia/stdlib/v1.8/Serialization/src/\u001b[39m\u001b[90m\u001b[4mSerialization.jl:813\u001b[24m\u001b[39m\n  [4] \u001b[0m\u001b[1mhandle_deserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/Applications/Julia-1.8.app/Contents/Resources/julia/share/julia/stdlib/v1.8/Serialization/src/\u001b[39m\u001b[90m\u001b[4mSerialization.jl:873\u001b[24m\u001b[39m\n  [5] \u001b[0m\u001b[1mdeserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/Applications/Julia-1.8.app/Contents/Resources/julia/share/julia/stdlib/v1.8/Serialization/src/\u001b[39m\u001b[90m\u001b[4mSerialization.jl:813\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n  [6] \u001b[0m\u001b[1mdeserialize_msg\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/Applications/Julia-1.8.app/Contents/Resources/julia/share/julia/stdlib/v1.8/Distributed/src/\u001b[39m\u001b[90m\u001b[4mmessages.jl:87\u001b[24m\u001b[39m\n  [7] \u001b[0m\u001b[1m#invokelatest#2\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4messentials.jl:729\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n  [8] \u001b[0m\u001b[1minvokelatest\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4messentials.jl:726\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n  [9] \u001b[0m\u001b[1mmessage_handler_loop\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/Applications/Julia-1.8.app/Contents/Resources/julia/share/julia/stdlib/v1.8/Distributed/src/\u001b[39m\u001b[90m\u001b[4mprocess_messages.jl:176\u001b[24m\u001b[39m\n [10] \u001b[0m\u001b[1mprocess_tcp_streams\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/Applications/Julia-1.8.app/Contents/Resources/julia/share/julia/stdlib/v1.8/Distributed/src/\u001b[39m\u001b[90m\u001b[4mprocess_messages.jl:133\u001b[24m\u001b[39m\n [11] \u001b[0m\u001b[1m#103\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mtask.jl:484\u001b[24m\u001b[39m",
      "",
      "Stacktrace:",
      "  [1] (::Base.var\"#939#941\")(x::Task)",
      "    @ Base ./asyncmap.jl:177",
      "  [2] foreach(f::Base.var\"#939#941\", itr::Vector{Any})",
      "    @ Base ./abstractarray.jl:2774",
      "  [3] maptwice(wrapped_f::Function, chnl::Channel{Any}, worker_tasks::Vector{Any}, c::Vector{Int64})",
      "    @ Base ./asyncmap.jl:177",
      "  [4] wrap_n_exec_twice",
      "    @ ./asyncmap.jl:153 [inlined]",
      "  [5] #async_usemap#924",
      "    @ ./asyncmap.jl:103 [inlined]",
      "  [6] #asyncmap#923",
      "    @ ./asyncmap.jl:81 [inlined]",
      "  [7] pmap(f::Function, p::WorkerPool, c::Vector{Int64}; distributed::Bool, batch_size::Int64, on_error::Nothing, retry_delays::Vector{Any}, retry_check::Nothing)",
      "    @ Distributed /Applications/Julia-1.8.app/Contents/Resources/julia/share/julia/stdlib/v1.8/Distributed/src/pmap.jl:126",
      "  [8] pmap(f::Function, p::WorkerPool, c::Vector{Int64})",
      "    @ Distributed /Applications/Julia-1.8.app/Contents/Resources/julia/share/julia/stdlib/v1.8/Distributed/src/pmap.jl:99",
      "  [9] pmap(f::Function, c::Vector{Int64}; kwargs::Base.Pairs{Symbol, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})",
      "    @ Distributed /Applications/Julia-1.8.app/Contents/Resources/julia/share/julia/stdlib/v1.8/Distributed/src/pmap.jl:156",
      " [10] pmap(f::Function, c::Vector{Int64})",
      "    @ Distributed /Applications/Julia-1.8.app/Contents/Resources/julia/share/julia/stdlib/v1.8/Distributed/src/pmap.jl:156",
      " [11] top-level scope",
      "    @ ./timing.jl:262 [inlined]",
      " [12] top-level scope",
      "    @ ./In[26]:0",
      " [13] eval",
      "    @ ./boot.jl:368 [inlined]",
      " [14] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1428"
     ]
    }
   ],
   "source": [
    "@time pmap(countHeads,num_coins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is the regular version of the `map` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 23.979835 seconds (46.62 k allocations: 2.384 MiB, 0.17% compilation time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12-element Vector{Int64}:\n",
       " 500013495\n",
       " 500003571\n",
       " 499994721\n",
       " 499977769\n",
       " 499997136\n",
       " 500000355\n",
       " 499982740\n",
       " 500018941\n",
       " 499993033\n",
       " 499984270\n",
       " 500008373\n",
       " 500020481"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time map(countHeads,num_coins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 18.4 Shared Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the hard things to code in parallel manner is when there is something that needs to be accessed in a parallel manner.  It's difficult to just break up the code.  This example shows that when we have a array that we wish to smooth out, we can use a Shared Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = [50+50*sin(x/1_000_000)+25*rand() for x=1:10_000_000];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(arr[1:5000:end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function does a windowed mean, that is for a part of the array it calculates the mean of a subarray. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function windowMean(arr::Vector{T},i::Integer,width::Integer) where T <: Real\n",
    "  ## find a range of the window, making sure that it doesn't go beyond the bounds of the array\n",
    "  window = max(1,i-width):min(i+width,length(arr))  \n",
    "  sum(arr[window])/(last(window)-first(window)+1)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This now smooths the array, storing the results in `smoothed_array`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_array = zeros(Float64,length(arr));\n",
    "@time let\n",
    "  for i=1:length(arr)\n",
    "    smoothed_array[i]=windowMean(arr,i,100)\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(arr[1:5000:end])\n",
    "plot!(smoothed_array[1:5000:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function windowMean(arr::Vector{T},i::Integer,width::Integer) where T <: Real\n",
    "  ## find a range of the window, making sure that it doesn't go beyond the bounds of the array\n",
    "  window = max(1,i-width):min(i+width,length(arr))  \n",
    "  sum(arr[window])/(last(window)-first(window)+1)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using SharedArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere arr = [50+50*sin(x/1_000_000)+25*rand() for x=1:10_000_000];\n",
    "@everywhere orig_arr = SharedVector(arr);\n",
    "@everywhere s_arr = SharedVector(zeros(Float64,length(orig_arr)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time let\n",
    "  @sync @distributed for i=1:length(orig_arr)\n",
    "    s_arr[i]=windowMean(arr,i,100)\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(orig_arr[1:5000:end])\n",
    "plot!(s_arr[1:5000:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
